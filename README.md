# Flan-T5-Small-FineTune-SQuAd

This repository demonstrates the fine-tuning of the `bert-base-uncased` model on the SQuAD (Stanford Question Answering Dataset) and provides a Streamlit-based application for question answering. The application allows users to compare the performance of the fine-tuned model with the base model on custom or predefined questions and contexts.

---

## Table of Contents
- [Features](#features)
- [Setup and Installation](#setup-and-installation)
- [Usage](#usage)
- [Directory Structure](#directory-structure)
- [Files Description](#files-description)
- [Acknowledgements](#acknowledgements)

---

## Features
- Fine-tunes a pre-trained `bert-base-uncased` model on a subset of the SQuAD dataset.
- Provides a Streamlit web app to:
  - Input custom context and questions.
  - Compare the answers generated by the fine-tuned model and the base model.
  - Select random predefined question-context pairs for testing.

---

## Setup and Installation

1. **Clone the repository**:
    ```bash
    git clone https://github.com/sujal-maheshwari2004/BERT-FineTune-SQuAd.git
    cd BERT-FineTune-SQuAd
    ```

2. **Install the required dependencies**:
    ```bash
    pip install -r requirements.txt
    ```

3. **Fine-tune the model (optional)**:
    If you want to re-run the fine-tuning process:
    ```bash
    python fine_tune.py
    ```
    This will save the fine-tuned model in a directory named `./fine_tuned_model`.

4. **Run the Streamlit app**:
    ```bash
    streamlit run app.py
    ```

---

## Usage

1. Open the Streamlit app in your browser.
2. Input a custom question and context or use the "Get Random Sample" button to select predefined ones.
3. Compare the answers generated by:
   - The fine-tuned model.
   - The base BERT model (`bert-base-uncased`).

---

## Directory Structure

```
Flan-T5-Small-FineTune-SQuAd/
â”œâ”€â”€ README.md                # Project documentation
â”œâ”€â”€ app.py                   # Streamlit application for QA demonstration
â”œâ”€â”€ fine_tune.py             # Fine-tuning script
â”œâ”€â”€ requirements.txt         # Dependencies
â””â”€â”€ fine_tuned_model/        # Saved fine-tuned model (created after running fine_tune.py)
```

---

## Files Description

### 1. `app.py`
A Streamlit-based UI to compare question-answering capabilities of the fine-tuned model with the base model.  
Key features:
- Custom question and context inputs.
- Predefined question-context samples.
- Tokenization and inference using Hugging Face Transformers.

### 2. `fine_tune.py`
Fine-tunes the `bert-base-uncased` model on the SQuAD dataset.  
Key functionalities:
- Loads and preprocesses the SQuAD dataset.
- Fine-tunes the model using the Hugging Face `Trainer`.
- Saves the fine-tuned model and metrics for later use.

### 3. `requirements.txt`
Lists all the dependencies required to run the project.

---

## Acknowledgements

- [Hugging Face Transformers](https://huggingface.co/transformers/): For providing pre-trained models and tools for fine-tuning.
- [Streamlit](https://streamlit.io/): For building the web app interface.
- [SQuAD Dataset](https://rajpurkar.github.io/SQuAD-explorer/): The Stanford Question Answering Dataset used for training and evaluation.

---

Enjoy experimenting with question answering! If you have suggestions or encounter issues, feel free to raise an issue or contribute to the repository. ðŸ˜Š
